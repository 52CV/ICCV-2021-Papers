# ICCV2021æœ€æ–°ä¿¡æ¯åŠå·²æ¥æ”¶è®ºæ–‡/ä»£ç (æŒç»­æ›´æ–°)

<div align="center">
  <img src="image/ICCV2021.png"/>
</div>

å®˜ç½‘é“¾æ¥ï¼šhttp://iccv2021.thecvf.com/home<br>
å¼€ä¼šæ—¶é—´ï¼š2021å¹´10æœˆ11æ—¥è‡³17æ—¥<br>

# ğŸ“—ğŸ“—ğŸ“—åœ¨ã€æˆ‘çˆ±è®¡ç®—æœºè§†è§‰ã€‘å¾®ä¿¡å…¬ä¼—å·åå°å›å¤â€œpaperâ€ï¼Œå³å¯æ”¶åˆ° ICCV 2021 å·²æ”¶å½•è®ºæ–‡çš„æ‰“åŒ…ä¸‹è½½ã€‚è‡³8æœˆ16æ—¥å·²å…¬å¼€ 179 ç¯‡ã€‚

## :exclamation::exclamation::exclamation::star2::star2::star2:ICCV 2021æ”¶å½•è®ºæ–‡ï¼Œ8æœˆ16æ—¥æ–°å¢ 5 ç¯‡ã€‚
* åˆ†å‰²
  * [Dual Path Learning for Domain Adaptation of Semantic Segmentation](https://arxiv.org/abs/2108.06337)<br>:star:[code](https://github.com/royee182/DPL)
* ç›®æ ‡æ£€æµ‹
  * [Conditional DETR for Fast Training Convergence](https://arxiv.org/abs/2108.06152)
* Out-of-Distribution Detection
  * [CODEs: Chamfer Out-of-Distribution Examples against Overconfidence Issue](https://arxiv.org/abs/2108.06024)
* å¯¹æŠ—
  * [AGKD-BML: Defense Against Adversarial Attack by Attention Guided Knowledge Distillation and Bi-directional Metric Learning](https://arxiv.org/abs/2108.06017)<br>:star:[code](https://github.com/hongw579/AGKD-BML)
* Image quality assessment (IQA) å›¾åƒè´¨é‡è¯„ä¼°
  * [MUSIQ: Multi-scale Image Quality Transformer](https://arxiv.org/abs/2108.05997)<br>:star:[code](https://github.com/google-research/google-research/tree/master/musiq)

### 8æœˆ13æ—¥æ–°å¢ 18 ç¯‡ã€‚
* çŸ¥è¯†è’¸é¦
  * [Distilling Holistic Knowledge with Graph Neural Networks](https://arxiv.org/abs/2108.05507)<br>:star:[code](https://github.com/wyc-ruiker/HKD)
* å§¿æ€
  * [HandFoldingNet: A 3D Hand Pose Estimation Network Using Multiscale-Feature Guided Folding of a 2D Hand Skeleton](https://arxiv.org/abs/2108.05545)<br>:star:[code](https://github.com/cwc1260/HandFold)
* åŠç›‘ç£
  * [Trash to Treasure: Harvesting OOD Data with Cross-Modal Matching for Open-Set Semi-Supervised Learning](https://arxiv.org/abs/2108.05617)
* åˆ†å‰²
  * [LabOR: Labeling Only if Required for Domain Adaptive Semantic Segmentation](https://arxiv.org/abs/2108.05570)<br>:open_mouth:oral
  * [Vision-Language Transformer and Query Generation for Referring Segmentation](https://arxiv.org/abs/2108.05565)<br>:star:[code](https://github.com/henghuiding/Vision-Language-Transformer)
* ç›®æ ‡æ£€æµ‹
  * [Oriented R-CNN for Object Detection](https://arxiv.org/abs/2108.05699)<br>:star:[code](https://github.com/jbwang1997/OBBDetection)
* åŸŸé€‚åº”
  * [Semantic Concentration for Domain Adaptation](https://arxiv.org/abs/2108.05720)<br>:star:[code](https://github.com/BIT-DA)
* ç‚¹äº‘
  * [AdaFit: Rethinking Learning-based Normal Estimation on Point Clouds](https://arxiv.org/abs/2108.05836)<br>:star:[code](https://github.com/Runsong123/AdaFit):house:[project](https://runsong123.github.io/AdaFit/)
* åˆ†ç±»
  * [DiagViB-6: A Diagnostic Benchmark Suite for Vision Models in the Presence of Shortcut and Generalization Opportunities](https://arxiv.org/abs/2108.05779)
* å›¾åƒè¯†åˆ«
  * [MicroNet: Improving Image Recognition with Extremely Low FLOPs](https://arxiv.org/abs/2108.05894)<br>:star:[code](https://github.com/liyunsheng13/micronet)
* 3D
  * [PixelSynth: Generating a 3D-Consistent Experience from a Single Image](https://arxiv.org/abs/2108.05892)<br>:star:[code](https://github.com/crockwell/pixelsynth):house:[project](https://crockwell.github.io/pixelsynth/)
  * [Towers of Babel: Combining Images, Language, and 3D Geometry for Learning Multimodal Vision](https://arxiv.org/abs/2108.05863)<br>:star:[code](https://github.com/tgxs002/wikiscenes):house:[project](https://www.cs.cornell.edu/projects/babel/)
* Metric Learning(åº¦é‡å­¦ä¹ )
  * [Towards Interpretable Deep Metric Learning with Structural Matching](https://arxiv.org/abs/2108.05889)<br>:star:[code](https://github.com/wl-zhao/DIML)
* SGG
  * [Unconditional Scene Graph Generation](https://arxiv.org/abs/2108.05884)<br>:house:[project](https://scenegraphgen.github.io/)
* ç±»å¢é‡å­¦ä¹ 
  * [Always Be Dreaming: A New Approach for Data-Free Class-Incremental Learning](https://arxiv.org/abs/2106.09701)<br>:newspaper:è§£è¯»:[è®©æ¨¡å‹å®ç°â€œç»ˆç”Ÿå­¦ä¹ â€ï¼Œä½æ²»äºšç†å·¥å­¦é™¢æå‡ºData-Freeçš„å¢é‡å­¦ä¹ ](https://mp.weixin.qq.com/s/Fm9ufPD6rzL2VzaqpdFpjg)
* å…¶å®ƒ
  * [m-RevNet: Deep Reversible Neural Networks with Momentum](https://arxiv.org/abs/2108.05862)
  * [Continual Neural Mapping: Learning An Implicit Scene Representation from Sequential Observations](https://arxiv.org/abs/2108.05851)
  * [MT-ORL: Multi-Task Occlusion Relationship Learning](https://arxiv.org/abs/2108.05722)<br>:star:[code](https://github.com/fengpanhe/MT-ORL)

# ç›®å½•

|:dog:|:mouse:|:hamster:|:tiger:|
|------|------|------|------|
|[41.Out-of-Distribution Detection(OOD)](#41)|
|[37.Multitask Learning(å¤šä»»åŠ¡å­¦ä¹ )](#37)|[38.Weakly/Semi-Supervised/Self-supervised/Unsupervised Learning(è‡ª/åŠ/å¼±ç›‘ç£å­¦ä¹ )](#38)|[39.Incremental Learning(å¢é‡å­¦ä¹ )](#39)|[40.Metric Learning(åº¦é‡å­¦ä¹ )](#40)|
|[33.Remote Sensing Images(é¥æ„Ÿå½±åƒ)](#33)|[34.Image Super-Resolution(å›¾åƒè¶…åˆ†è¾¨ç‡)](#34)|[35.Quantization/Pruning/Knowledge Distillation/Model Compression(é‡åŒ–ã€å‰ªæã€è’¸é¦ã€æ¨¡å‹å‹ç¼©/æ‰©å±•ä¸ä¼˜åŒ–)](#35)|[36.SLAM/AR/VR/æœºå™¨äºº](#36)|
|[29.Image Retrieval(å›¾åƒæ£€ç´¢)](#29)|[30.Image Generation/synthesis(å›¾åƒç”Ÿæˆ/åˆæˆ)](#30)|[31.Style Transfer(é£æ ¼è¿ç§»)](#31)|[32.è¯­éŸ³](#32)|
|[25.Medical Image(åŒ»å­¦å½±åƒ)](#25)|[26.Image Processing(å›¾åƒå¤„ç†)](#26)|[27.Multi-label image recognition(å¤šæ ‡ç­¾å›¾åƒè¯†åˆ«)](#27)|[28.Contrastive Learning(å¯¹æ¯”å­¦ä¹ )](#28)]
|[21.Active Learning(ä¸»åŠ¨å­¦ä¹ )](#21)|[22.GAN](#22)|[23.Gaze Estimation(è§†çº¿ä¼°è®¡)](#23)|[24.Face(äººè„¸)](#24)|
|[17.3D(ä¸‰ç»´è§†è§‰)](#17)|[18.Transformers](#18)|[19.Self-Driving Vehicles(è‡ªåŠ¨é©¾é©¶)](#19)|[20.Adversarial Learning(å¯¹æŠ—å­¦ä¹ )](#20)|
|[13.Image Segmentation(å›¾åƒåˆ†å‰²)](#13)|[14.Object Detection(ç›®æ ‡æ£€æµ‹)](#13)|[15.Object Tracking(ç›®æ ‡è·Ÿè¸ª)](#15)|[16.Person Re-Identification(äººå‘˜é‡è¯†åˆ«)](#16)|
|[9.Video](#9)|[10.OCR](10)|[11.Visual Question Answering(è§†è§‰é—®ç­”)](#11)|[12.Image/Fine-Grained Classification(å›¾åƒ/ç»†ç²’åº¦åˆ†ç±»)](#12)|
|[5.Few-Shot/Zero-Shot Learning;Domain Generalization/Adaptation(å°/é›¶æ ·æœ¬å­¦ä¹ ;åŸŸé€‚åº”/æ³›åŒ–)](#5)|[6.Point Cloud(ç‚¹äº‘)](#6)|[7.Scene Graph Generation(åœºæ™¯å›¾ç”Ÿæˆ)](#7)|[8.Human Pose Estimation(äººä½“å§¿æ€ä¼°è®¡)](#8)|
|[1.Other(å…¶å®ƒ)](#1)|[2.Sign Language(æ‰‹è¯­è¯†åˆ«)](#2)|[3.Image Clustering(å›¾åƒèšç±»)](#3)|[4.Neural rendering(ç¥ç»æ¸²æŸ“)](#4)|




<a name="41"/>

## 41.Out-of-Distribution Detection(OOD)
* [CODEs: Chamfer Out-of-Distribution Examples against Overconfidence Issue](https://arxiv.org/abs/2108.06024)

<a name="40"/>

## 40.Metric Learning(åº¦é‡å­¦ä¹ )
* [Towards Interpretable Deep Metric Learning with Structural Matching](https://arxiv.org/abs/2108.05889)<br>:star:[code](https://github.com/wl-zhao/DIML)

<a name="39"/>

## 39.Incremental Learning(å¢é‡å­¦ä¹ )
* ç±»å¢é‡å­¦ä¹ 
  * [Always Be Dreaming: A New Approach for Data-Free Class-Incremental Learning](https://arxiv.org/abs/2106.09701)<br>:newspaper:è§£è¯»:[è®©æ¨¡å‹å®ç°â€œç»ˆç”Ÿå­¦ä¹ â€ï¼Œä½æ²»äºšç†å·¥å­¦é™¢æå‡ºData-Freeçš„å¢é‡å­¦ä¹ ](https://mp.weixin.qq.com/s/Fm9ufPD6rzL2VzaqpdFpjg)

<a name="38"/>

## 38.Weakly/Semi-Supervised/Self-supervised/Unsupervised Learning(è‡ª/åŠ/å¼±ç›‘ç£å­¦ä¹ )
* åŠç›‘ç£
  * [Trash to Treasure: Harvesting OOD Data with Cross-Modal Matching for Open-Set Semi-Supervised Learning](https://arxiv.org/abs/2108.05617)

<a name="37"/>

## 37.Multitask Learning(å¤šä»»åŠ¡å­¦ä¹ )
* [MultiTask-CenterNet (MCN): Efficient and Diverse Multitask Learning using an Anchor Free Approach](https://arxiv.org/abs/2108.05060)

<a name="36"/>

## 36.SLAM/AR/VR/æœºå™¨äºº
* è™šæ‹Ÿè¯•ç©¿  
  * [M3D-VTON: A Monocular-to-3D Virtual Try-On Network](https://arxiv.org/abs/2108.05126)

<a name="35"/>

## 35.Quantization/Pruning/Knowledge Distillation/Model Compression(é‡åŒ–ã€å‰ªæã€è’¸é¦ã€æ¨¡å‹å‹ç¼©/æ‰©å±•ä¸ä¼˜åŒ–)
* çŸ¥è¯†è’¸é¦
  * [Distilling Holistic Knowledge with Graph Neural Networks](https://arxiv.org/abs/2108.05507)<br>:star:[code](https://github.com/wyc-ruiker/HKD)


<a name="34"/>

## 34.Image Super-Resolution(å›¾åƒè¶…åˆ†è¾¨ç‡)
* [Mutual Affine Network for Spatially Variant Kernel Estimation in Blind Image Super-Resolution](https://arxiv.org/abs/2108.05302)<br>:star:[code](https://github.com/JingyunLiang/MANet)
* [Hierarchical Conditional Flow: A Unified Framework for Image Super-Resolution and Image Rescaling](https://arxiv.org/abs/2108.05301)<br>:star:[code](https://github.com/JingyunLiang/HCFlow)

<a name="33"/>

## 33.Remote Sensing Images(é¥æ„Ÿå½±åƒ)
* [SUNet: Symmetric Undistortion Network for Rolling Shutter Correction](https://arxiv.org/abs/2108.04775)

<a name="32"/>

## 32.è¯­éŸ³
* [The Right to Talk: An Audio-Visual Transformer Approach](https://arxiv.org/abs/2108.03256)<br>:star:[code](https://github.com/uark-cviu/Right2Talk)

<a name="31"/>

## 31.Style Transfer(é£æ ¼è¿ç§»)
* [AdaAttN: Revisit Attention Mechanism in Arbitrary Neural Style Transfer](https://arxiv.org/abs/2108.03647)<br>:star:[code](https://github.com/Huage001/AdaAttN)
* [Domain-Aware Universal Style Transfer](https://arxiv.org/abs/2108.04441)<br>:star:[code](https://github.com/Kibeom-Hong/Domain-Aware-Style-Transfer)

<a name="30"/>

## 30.Image Generation/synthesis(å›¾åƒç”Ÿæˆ/åˆæˆ)
  * [ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2108.02938)<br>:open_mouth:oral

<a name="29"/>

## 29.Image Retrieval(å›¾åƒæ£€ç´¢)
  * [DOLG: Single-Stage Image Retrieval with Deep Orthogonal Fusion of Local and Global Features](https://arxiv.org/abs/2108.02927)<br>:star:[code](https://github.com/feymanpriv/DOLG)
  * [Image Retrieval on Real-life Images with Pre-trained Vision-and-Language Models](https://arxiv.org/abs/2108.04024)<br>:star:[code](https://github.com/Cuberick-Orion/CIRR):house:[project](https://cuberick-orion.github.io/CIRR/)


<a name="28"/>

## 28.Contrastive Learning(å¯¹æ¯”å­¦ä¹ )
  * [Improving Contrastive Learning by Visualizing Feature Transformation](https://arxiv.org/abs/2108.02982)<br>:open_mouth:oral:star:[code](https://github.com/DTennant/CL-Visualizing-Feature-Transformation)

<a name="27"/>

## 27.Multi-label image recognition(å¤šæ ‡ç­¾å›¾åƒè¯†åˆ«)
* [Residual Attention: A Simple but Effective Method for Multi-Label Recognition](https://arxiv.org/abs/2108.02456)

<a name="26"/>

## 26.Image Processing(å›¾åƒå¤„ç†)

* è¾¹ç¼˜æ£€æµ‹
  * [RINDNet: Edge Detection for Discontinuity in Reflectance, Illumination, Normal and Depth](https://arxiv.org/abs/2108.00616)<br>:open_mouth:oral:star:[code](https://github.com/MengyangPu/RINDNet)
* å›¾åƒè¯†åˆ«
  * [MicroNet: Improving Image Recognition with Extremely Low FLOPs](https://arxiv.org/abs/2108.05894)<br>:star:[code](https://github.com/liyunsheng13/micronet)
* å›¾åƒå»æ¨¡ç³Š
  * [Rethinking Coarse-to-Fine Approach in Single Image Deblurring](https://arxiv.org/abs/2108.05054)<br>:star:[code](https://github.com/chosj95/MIMO-UNet)
* Image quality assessment(å›¾åƒè´¨é‡è¯„ä¼°IQA)
  * [MUSIQ: Multi-scale Image Quality Transformer](https://arxiv.org/abs/2108.05997)<br>:star:[code](https://github.com/google-research/google-research/tree/master/musiq)


<a name="25"/>

## 25.Medical Image(åŒ»å­¦å½±åƒ)
* åŒ»å­¦å›¾åƒåˆ†å‰²
  * [Recurrent Mask Refinement for Few-Shot Medical Image Segmentation](https://arxiv.org/abs/2108.00622)<br>:star:[code](https://github.com/uci-cbcl/RP-Net)
  
<a name="24"/>

## 24.Face(äººè„¸)
* äººè„¸é€ å‡æ£€æµ‹
  * [OpenForensics: Large-Scale Challenging Dataset For Multi-Face Forgery Detection And Segmentation In-The-Wild](https://arxiv.org/abs/2107.14480)<br>:house:[project](https://sites.google.com/view/ltnghia/research/openforensics)
* äººè„¸åˆæˆ
  * [Disentangled Lifespan Face Synthesis](https://arxiv.org/abs/2108.02874)<br>:star:[code](https://github.com/SenHe/DLFS):house:[project](https://senhe.github.io/projects/iccv_2021_lifespan_face/):tv:[video](https://youtu.be/uklX03ns0m0)
* äººè„¸è¯†åˆ«                                                                                      
  * [PASS: Protected Attribute Suppression System for Mitigating Bias in Face Recognition](https://arxiv.org/abs/2108.03764)
* Face perceptioné¢éƒ¨æ„ŸçŸ¥
 * [Learning Facial Representations from the Cycle-consistency of Face](https://arxiv.org/abs/2108.03427)<br>:star:[code](https://github.com/JiaRenChang/FaceCycle)

<a name="23"/>

## 23.Gaze Estimation(è§†çº¿ä¼°è®¡)
* [Generalizing Gaze Estimation with Outlier-guided Collaborative Adaptation](https://arxiv.org/abs/2107.13780)<br>:star:[code](https://github.com/DreamtaleCore/PnP-GA)

<a name="22"/>

## 22.GAN
* [Sketch Your Own GAN](https://arxiv.org/abs/2108.02774)<br>:star:[code](https://github.com/peterwang512/GANSketching):house:[project](https://peterwang512.github.io/GANSketching/)
* GAN inversion(GANé€†æ˜ å°„)
  * [From Continuity to Editability: Inverting GANs with Consecutive Images](https://arxiv.org/abs/2107.13812)<br>:star:[code](https://github.com/cnnlstm/InvertingGANs_with_ConsecutiveImgs)

<a name="21"/>

## 21.Active Learning(ä¸»åŠ¨å­¦ä¹ )
* [Semi-Supervised Active Learning with Temporal Output Discrepancy](https://arxiv.org/abs/2107.14153)<br>:star:[code](https://github.com/siyuhuang/TOD)

<a name="20"/>

## 20.Adversarial Learning(å¯¹æŠ—å­¦ä¹ )
* [Feature Importance-aware Transferable Adversarial Attacks](https://arxiv.org/abs/2107.14185)<br>:star:[code](https://github.com/hcguoO0/FIA)
* [TkML-AP: Adversarial Attacks to Top-k Multi-Label Learning](https://arxiv.org/abs/2108.00146)
* [Meta Gradient Adversarial Attack](https://arxiv.org/abs/2108.04204)
* [AGKD-BML: Defense Against Adversarial Attack by Attention Guided Knowledge Distillation and Bi-directional Metric Learning](https://arxiv.org/abs/2108.06017)<br>:star:[code](https://github.com/hongw579/AGKD-BML)

<a name="19"/>

## 19.Self-Driving Vehicles(è‡ªåŠ¨é©¾é©¶)
* Human trajectory prediction(äººä½“è½¨è¿¹é¢„æµ‹)
  * [Personalized Trajectory Prediction via Distribution Discrimination](https://arxiv.org/abs/2107.14204)<br>:star:[code](https://github.com/CHENGY12/DisDis)
  * [Human Trajectory Prediction via Counterfactual Analysis](https://arxiv.org/abs/2107.14202)(https://github.com/CHENGY12/CausalHTP)
* è½¨è¿¹é¢„æµ‹
  * [Unlimited Neighborhood Interaction for Heterogeneous Trajectory Prediction](https://arxiv.org/abs/2108.00238)
* è¿åŠ¨é¢„æµ‹
  * [RAIN: Reinforced Hybrid Attention Inference Network for Motion Forecasting](https://arxiv.org/abs/2108.01316)<br>:house:[project](https://jiachenli94.github.io/publications/RAIN/)
  * [SLAMP: Stochastic Latent Appearance and Motion Prediction](https://arxiv.org/abs/2108.02760)<br>:house:[project](https://peterwang512.github.io/GANSketching/)(https://kuis-ai.github.io/slamp/)


<a name="18"/>

## 18.Transformers
* [Generic Attention-model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers](https://arxiv.org/abs/2103.15679)<br>:open_mouth:oral:star:[code](https://github.com/hila-chefer/Transformer-MM-Explainability)<br>:newspaper:è§£è¯»:[ICCV2021 Oral-TAU&Facebookæå‡ºäº†é€šç”¨çš„Attentionæ¨¡å‹å¯è§£é‡Šæ€§](https://mp.weixin.qq.com/s/3skb8XMiwM3QtdH7ZazoYg)
* [PlaneTR: Structure-Guided Transformers for 3D Plane Recovery](https://arxiv.org/abs/2107.13108)<br>:star:[code](https://github.com/IceTTTb/PlaneTR3D)
* [Rethinking and Improving Relative Position Encoding for Vision Transformer](https://arxiv.org/abs/2107.14222)<br>:star:[code](https://github.com/microsoft/AutoML/tree/main/iRPE)
* [Vision Transformer with Progressive Sampling](https://arxiv.org/abs/2108.01684)
* [Paint Transformer: Feed Forward Neural Painting with Stroke Prediction](https://arxiv.org/abs/2108.03798)<br>:open_mouth:oral:star:[code](https://github.com/Huage001/PaintTransformer)
* å¯†é›†é¢„æµ‹
  * [Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions](https://arxiv.org/abs/2102.12122)<br>:open_mouth:oral:star:[code](https://github.com/whai362/PVT)<br>:newspaper:è§£è¯»:[å¤§ç™½è¯Pyramid Vision Transformer](https://mp.weixin.qq.com/s/oJHZWmStQYYzEEOveiuQrQ)



<a name="17"/>

## 17.3D(ä¸‰ç»´è§†è§‰)
* [Discovering 3D Parts from Image Collections](https://arxiv.org/abs/2107.13629)<br>:open_mouth:oral:star:[code](https://github.com/chhankyao/lpd):house:[project](https://chhankyao.github.io/lpd/):tv:[video](https://youtu.be/erNQANNwK6k)
* [PixelSynth: Generating a 3D-Consistent Experience from a Single Image](https://arxiv.org/abs/2108.05892)<br>:star:[code](https://github.com/crockwell/pixelsynth):house:[project](https://crockwell.github.io/pixelsynth/)
* [Towers of Babel: Combining Images, Language, and 3D Geometry for Learning Multimodal Vision](https://arxiv.org/abs/2108.05863)<br>:star:[code](https://github.com/tgxs002/wikiscenes):house:[project](https://www.cs.cornell.edu/projects/babel/)
* Monocular Depth Estimation(å•ç›®æ·±åº¦ä¼°è®¡)
  * [MonoIndoor: Towards Good Practice of Self-Supervised Monocular Depth Estimation for Indoor Environments](https://arxiv.org/abs/2107.12429)
  * [Regularizing Nighttime Weirdness: Efficient Self-supervised Monocular Depth Estimation in the Dark](https://arxiv.org/abs/2108.03830)<br>:star:[code](https://github.com/w2kun/RNW)
  * [Towards Interpretable Deep Networks for Monocular Depth Estimation](https://arxiv.org/abs/2108.05312)<br>:star:[code](https://github.com/youzunzhi/InterpretableMDE)



<a name="16"/>

## 16.Person Re-Identification(äººå‘˜é‡è¯†åˆ«)
* [Spatio-Temporal Representation Factorization for Video-based Person Re-Identification](https://arxiv.org/abs/2107.11878)
* [Learning Instance-level Spatial-Temporal Patterns for Person Re-identification](https://arxiv.org/abs/2108.00171)<br>:star:[code](https://github.com/RenMin1991/cleaned-DukeMTMC-reID/)
* [Towards Discriminative Representation Learning for Unsupervised Person Re-identification](https://arxiv.org/abs/2108.03439)
* åŸŸé€‚åº”äººå‘˜é‡è¯†åˆ«
  * [IDM: An Intermediate Domain Module for Domain Adaptive Person Re-ID](https://arxiv.org/abs/2108.02413)<br>:open_mouth:oral:star:[code](https://github.com/SikaStar/IDM)
* Crowd Counting(æ‹¥æŒ¤äººç¾¤è®¡æ•°)
  * [Rethinking Counting and Localization in Crowds:A Purely Point-Based Framework](https://arxiv.org/abs/2107.12746)<br>:open_mouth:oral:star:[code](https://github.com/TencentYoutuResearch)
  * [Uniformity in Heterogeneity:Diving Deep into Count Interval Partition for Crowd Counting](https://arxiv.org/abs/2107.12619)<br>:star:[code](https://github.com/TencentYoutuResearch)
  * [Spatial Uncertainty-Aware Semi-Supervised Crowd Counting](https://arxiv.org/abs/2107.13271)
* Person Search
  * [ASMR: Learning Attribute-Based Person Search with Adaptive Semantic Margin Regularizer](https://arxiv.org/abs/2108.04533)<br>:house:[project](http://cvlab.postech.ac.kr/research/ASMR/)


<a name="15"/>

## 15.Object Tracking(ç›®æ ‡è·Ÿè¸ª)
* [Saliency-Associated Object Tracking](https://arxiv.org/abs/2108.03637)
* [Box-Aware Feature Enhancement for Single Object Tracking on Point Clouds](https://arxiv.org/abs/2108.04728)<br>:star:[code](https://github.com/Ghostish/BAT)
* è§†è§‰ç›®æ ‡è·Ÿè¸ª
  * [Learning to Adversarially Blur Visual Object Tracking](https://arxiv.org/abs/2107.12085)<br>:star:[code](https://github.com/tsingqguo/ABA)
  * [Learn to Match: Automatic Matching Network Design for Visual Tracking](https://arxiv.org/abs/2108.00803)<br>:star:[code](https://github.com/JudasDie/SOTS)
  * [Video Annotation for Visual Tracking via Selection and Refinement](https://arxiv.org/abs/2108.03821)<br>:star:[code](https://github.com/Daikenan/VASR)
* å«æ˜Ÿå›¾åƒè·Ÿè¸ª 
  * [HiFT: Hierarchical Feature Transformer for Aerial Tracking](https://arxiv.org/abs/2108.00202)<br>:star:[code](https://github.com/vision4robotics/HiFT)

<a name="14"/>

## 14.Object Detection(ç›®æ ‡æ£€æµ‹)
* [Rank & Sort Loss for Object Detection and Instance Segmentation](https://arxiv.org/abs/2107.11669)<br>:open_mouth:oral:star:[code](https://github.com/kemaloksuz/RankSortLoss)
* [MDETR : Modulated Detection for End-to-End Multi-Modal Understanding](https://arxiv.org/abs/2104.12763)<br>:open_mouth:oral:star:[code](https://github.com/ashkamath/mdetr)
* [SimROD: A Simple Adaptation Method for Robust Object Detection](https://arxiv.org/abs/2107.13389)<br>:open_mouth:oral
* [GraphFPN: Graph Feature Pyramid Network for Object Detection](https://arxiv.org/abs/2108.00580)
* [Fast Convergence of DETR with Spatially Modulated Co-Attention](https://arxiv.org/abs/2108.02404)<br>:star:[code](https://github.com/gaopengcuhk/SMCA-DETR)
* [Oriented R-CNN for Object Detection](https://arxiv.org/abs/2108.05699)<br>:star:[code](https://github.com/jbwang1997/OBBDetection) 
* [Conditional DETR for Fast Training Convergence](https://arxiv.org/abs/2108.06152)
* 3Dç›®æ ‡æ£€æµ‹
  * [Geometry Uncertainty Projection Network for Monocular 3D Object Detection](https://arxiv.org/abs/2107.13774)
  * [Fog Simulation on Real LiDAR Point Clouds for 3D Object Detection in Adverse Weather](https://arxiv.org/abs/2108.05249)<br>:star:[code](https://github.com/MartinHahner/LiDAR_fog_sim):house:[project](https://www.trace.ethz.ch/publications/2021/lidar_fog_simulation/)
* ç›®æ ‡å®šä½
  * å¼±ç›‘ç£ç›®æ ‡å®šä½
    * [Normalization Matters in Weakly Supervised Object Localization](https://arxiv.org/abs/2107.13221)
* Anomaly Detection(å›¾åƒå¼‚å¸¸æ£€æµ‹)
  * [Divide-and-Assemble: Learning Block-wise Memory for Unsupervised Anomaly Detection](https://arxiv.org/abs/2107.13118)
* å¼±ç›‘ç£ç›®æ ‡æ£€æµ‹
  * [Boosting Weakly Supervised Object Detection via Learning Bounding Box Adjusters](https://arxiv.org/abs/2108.01499)<br>:star:[code](https://github.com/DongSky/lbba_boosted_wsod)
* OOD æ£€æµ‹
  * [Triggering Failures: Out-Of-Distribution detection by learning from local adversarial attacks in Semantic Segmentation](https://arxiv.org/abs/2108.01634)<br>:star:[code](https://github.com/valeoai/obsnet)
* æ˜¾è‘—ç›®æ ‡æ£€æµ‹
  * [Disentangled High Quality Salient Object Detection](https://arxiv.org/abs/2108.03551)


<a name="13"/>

## 13.Image Segmentation(å›¾åƒåˆ†å‰²)
* [Standardized Max Logits: A Simple yet Effective Approach for Identifying Unexpected Road Obstacles in Urban-Scene Segmentation](https://arxiv.org/abs/2107.11264)<br>:open_mouth:oral
* [TransForensics: Image Forgery Localization with Dense Self-Attention](https://arxiv.org/abs/2108.03871)
* è¯­ä¹‰åˆ†å‰²
  * [Re-distributing Biased Pseudo Labels for Semi-supervised Semantic Segmentation: A Baseline Investigation](https://arxiv.org/abs/2107.11279)<br>:open_mouth:oral:star:[code](https://github.com/CVMI-Lab/DARS)
  * [Personalized Image Semantic Segmentation](https://arxiv.org/abs/2107.13978)<br>:star:[code](https://github.com/zhangyuygss/PIS)
  * [RECALL: Replay-based Continual Learning in Semantic Segmentation](https://arxiv.org/abs/2108.03673)
  * [Deep Metric Learning for Open World Semantic Segmentation](https://arxiv.org/abs/2108.04562)
  * [LabOR: Labeling Only if Required for Domain Adaptive Semantic Segmentation](https://arxiv.org/abs/2108.05570)<br>:open_mouth:oral
  * [Dual Path Learning for Domain Adaptation of Semantic Segmentation](https://arxiv.org/abs/2108.06337)<br>:star:[code](https://github.com/royee182/DPL)
  * å°æ ·æœ¬è¯­ä¹‰åˆ†å‰²
    * [Simpler is Better: Few-shot Semantic Segmentation with Classifier Weight Transformer](https://arxiv.org/abs/2108.03032)<br>:star:[code](https://github.com/zhiheLu/CWT-for-FSS)
    * [Learning Meta-class Memory for Few-Shot Semantic Segmentation](https://arxiv.org/abs/2108.02958)
  * 3Dè¯­ä¹‰åˆ†å‰²
    * [VMNet: Voxel-Mesh Network for Geodesic-Aware 3D Semantic Segmentation](https://arxiv.org/abs/2107.13824)<br>:open_mouth:oral:star:[code](https://github.com/hzykent/VMNet)
  * è§†é¢‘è¯­ä¹‰åˆ†å‰²
    * [Domain Adaptive Video Segmentation via Temporal Consistency Regularization](https://arxiv.org/abs/2107.11004)<br>:star:[code](https://github.com/Dayan-Guan/DA-VSN)
  * å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²
    * [Leveraging Auxiliary Tasks with Affinity Learning for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2107.11787)<br>:star:[code](https://github.com/xulianuwa/AuxSegNet)
    * [Complementary Patch for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2108.03852)
  * ç‚¹äº‘è¯­ä¹‰åˆ†å‰²
    * [ReDAL: Region-based and Diversity-aware Active Learning for Point Cloud Semantic Segmentation](https://arxiv.org/abs/2107.11769)
* å®ä¾‹åˆ†å‰²
  * [Rank & Sort Loss for Object Detection and Instance Segmentation](https://arxiv.org/abs/2107.11669)<br>:open_mouth:oral:star:[code](https://github.com/kemaloksuz/RankSortLoss)
  * 3Då®ä¾‹åˆ†å‰²
    * [Hierarchical Aggregation for 3D Instance Segmentation](https://arxiv.org/abs/2108.02350)<br>:star:[code](https://github.com/hustvl/HAIS)
* å°æ ·æœ¬åˆ†å‰²
  * [Mining Latent Classes for Few-shot Segmentation](https://arxiv.org/abs/2103.15402)<br>:open_mouth:oral:star:[code](https://github.com/LiheYoung/MiningFSS)
* Human Motion Segmentation(äººä½“è¿åŠ¨åˆ†å‰²)
  * [Graph Constrained Data Representation Learning for Human Motion Segmentation](https://arxiv.org/abs/2107.13362)
* ç‚¹äº‘åˆ†å‰²
  * [Learning with Noisy Labels for Robust Point Cloud Segmentation](https://arxiv.org/abs/2107.14230)<br>:open_mouth:oral:star:[code](https://github.com/pleaseconnectwifi/PNAL):house:[project](https://shuquanye.com/PNAL_website/)
  * [DRINet: A Dual-Representation Iterative Learning Network for Point Cloud Segmentation](https://arxiv.org/abs/2108.04023)
* è§†é¢‘ç›®æ ‡åˆ†å‰²(VOS)
  * [Full-Duplex Strategy for Video Object Segmentation](https://arxiv.org/abs/2108.03151)<br>:house:[project](http://dpfan.net/FSNet/)
  * [Joint Inductive and Transductive Learning for Video Object Segmentation](https://arxiv.org/abs/2108.03679)<br>:star:[code](https://github.com/maoyunyao/JOINT)
* è¯­ä¹‰åœºæ™¯åˆ†å‰² 
  * [BiMaL: Bijective Maximum Likelihood Approach to Domain Adaptation in Semantic Scene Segmentation](https://arxiv.org/abs/2108.03267)<br>:star:[code](https://github.com/uark-cviu/BiMaL)
* Referring Segmentation(åŸºäºæ–‡æœ¬çš„åˆ†å‰²) 
  * [Vision-Language Transformer and Query Generation for Referring Segmentation](https://arxiv.org/abs/2108.05565)<br>:star:[code](https://github.com/henghuiding/Vision-Language-Transformer)



<a name="12"/>

## 12.Image/Fine-Grained Classification(å›¾åƒ/ç»†ç²’åº¦åˆ†ç±») 
* [DiagViB-6: A Diagnostic Benchmark Suite for Vision Models in the Presence of Shortcut and Generalization Opportunities](https://arxiv.org/abs/2108.05779)
* é•¿å°¾è¯†åˆ«
  * [Parametric Contrastive Learning](https://arxiv.org/abs/2107.12028)<br>:star:[code](https://github.com/jiequancui/Parametric-Contrastive-Learning)
  * [ACE: Ally Complementary Experts for Solving Long-Tailed Recognition in One-Shot](https://arxiv.org/abs/2108.02385)<br>:open_mouth:oral:star:[code](https://github.com/jrcai/ACE)
* ç»†ç²’åº¦
  * [Webly Supervised Fine-Grained Recognition: Benchmark Datasets and An Approach](https://arxiv.org/abs/2108.02399)<br>:star:[code](https://github.com/NUST-Machine-Intelligence-Laboratory/weblyFG-dataset)
  * [Learning Canonical 3D Object Representation for Fine-Grained Recognition](https://arxiv.org/abs/2108.04628)
* å°æ ·æœ¬åˆ†ç±»
  * [Transductive Few-Shot Classification on the Oblique Manifold](https://arxiv.org/abs/2108.04009)

<a name="11"/>

## 11.Visual Question Answering(è§†è§‰é—®ç­”)
* [Greedy Gradient Ensemble for Robust Visual Question Answering](https://arxiv.org/abs/2107.12651)<br>:star:[code](https://github.com/GeraldHan/GGE)
* video question answering
  * [Just Ask: Learning to Answer Questions from Millions of Narrated Videos](https://arxiv.org/abs/2012.00451)<br>:open_mouth:oral:star:[code](https://github.com/antoyang/just-ask):house:[project](https://antoyang.github.io/just-ask.html)

<a name="10"/>

## 10.OCR
* [Joint Visual Semantic Reasoning: Multi-Stage Decoder for Text Recognition](https://arxiv.org/abs/2107.12090)
* [Text is Text, No Matter What: Unifying Text Recognition using Knowledge Distillation](https://arxiv.org/abs/2107.12087)
* [Towards the Unseen: Iterative Text Recognition by Distilling from Errors](https://arxiv.org/abs/2107.12081)
* [Adaptive Boundary Proposal Network for Arbitrary Shape Text Detection](https://arxiv.org/abs/2107.12664)<br>:star:[code](https://github.com/GXYM/TextBPN)

<a name="9"/>

## 9.Video
* Action Detection and Recognition(äººä½“åŠ¨ä½œæ£€æµ‹ä¸è¯†åˆ«)
  * [Channel-wise Topology Refinement Graph Convolution for Skeleton-Based Action Recognition](https://arxiv.org/abs/2107.12213)<br>:star:[code](https://github.com/Uason-Chen/CTR-GCN)
  * [MGSampler: An Explainable Sampling Strategy for Video Action Recognition](https://arxiv.org/abs/2104.09952)
  * [Skeleton Cloud Colorization for Unsupervised 3D Action Representation Learning](https://arxiv.org/abs/2108.01959)
  * é›¶æ ·æœ¬åŠ¨ä½œè¯†åˆ«
    * [Elaborative Rehearsal for Zero-shot Action Recognition](https://arxiv.org/abs/2108.02833)<br>:star:[code](https://github.com/DeLightCMU/ElaborativeRehearsal)
  * Temporal Action Localization(æ—¶åºåŠ¨ä½œå®šä½)
    * [Enriching Local and Global Contexts for Temporal Action Localization](https://arxiv.org/abs/2107.12960)
    * [Learning Action Completeness from Points for Weakly-supervised Temporal Action Localization](https://arxiv.org/abs/2108.05029)<br>:open_mouth:oral:star:[code](https://github.com/Pilhyeon)
* Video Rescaling
  * [Self-Conditioned Probabilistic Learning of Video Rescaling](https://arxiv.org/abs/2107.11639)
* Video activity localisation
  * [Cross-Sentence Temporal and Semantic Relations in Video Activity Localisation](https://arxiv.org/abs/2107.11443)
* è§†é¢‘ä¿®å¤
  * [Internal Video Inpainting by Implicit Long-range Propagation](https://arxiv.org/abs/2108.01912)<br>:star:[code](https://github.com/Tengfei-Wang/Implicit-Internal-Video-Inpainting):house:[project](https://tengfei-wang.github.io/Implicit-Internal-Video-Inpainting/)
* è§†é¢‘åˆ†æ
  * è§†é¢‘è¡¨å¾å­¦ä¹ 
    * [Enhancing Self-supervised Video Representation Learning via Multi-level Feature Optimization](https://arxiv.org/abs/2108.02183)
* è§†é¢‘å‰ªè¾‘
  * [Learning to Cut by Watching Movies](https://arxiv.org/abs/2108.04294)<br>:star:[code](https://github.com/PardoAlejo/LearningToCut):house:[project](https://www.alejandropardo.net/publication/learning-to-cut/) 



<a name="8"/>

## 8.Human Pose Estimation(äººä½“å§¿æ€ä¼°è®¡)
* [Human Pose Regression with Residual Log-likelihood Estimation](https://arxiv.org/abs/2107.11291)<br>:open_mouth:oral:star:[code](https://github.com/Jeff-sjtu/res-loglikelihood-regression)
* [Online Knowledge Distillation for Efficient Pose Estimation](https://arxiv.org/abs/2108.02092)
* 3D äººä½“å§¿æ€ä¼°è®¡
  * [PyMAF: 3D Human Pose and Shape Regression with Pyramidal Mesh Alignment Feedback Loop](https://arxiv.org/abs/2103.16507)<br>:open_mouth:oral:star:[code](https://github.com/HongwenZhang/PyMAF):house:[project](https://hongwenzhang.github.io/pymaf/)
  * [HuMoR: 3D Human Motion Model for Robust Pose Estimation](https://arxiv.org/abs/2105.04668)<br>:open_mouth:oral:house:[project](https://geometry.stanford.edu/projects/humor/):tv:[video](https://youtu.be/5VWirxUHG0Y)
  * [Probabilistic Monocular 3D Human Pose Estimation with Normalizing Flows](https://arxiv.org/abs/2107.13788)<br>:star:[code](https://github.com/twehrbein/Probabilistic-Monocular-3D-Human-Pose-Estimation-with-Normalizing-Flows)
* æ‰‹åŠ¿è¯†åˆ«
  * [Hand Image Understanding via Deep Multi-Task Learning](https://arxiv.org/abs/2107.11646)
* 3D æ‰‹éƒ¨å§¿æ€
  * [HandFoldingNet: A 3D Hand Pose Estimation Network Using Multiscale-Feature Guided Folding of a 2D Hand Skeleton](https://arxiv.org/abs/2108.05545)<br>:star:[code](https://github.com/cwc1260/HandFold)


<a name="7"/>

## 7.Scene Graph Generation(åœºæ™¯å›¾ç”Ÿæˆ)
* [Spatial-Temporal Transformer for Dynamic Scene Graph Generation](https://arxiv.org/abs/2107.12309)
* [Unconditional Scene Graph Generation](https://arxiv.org/abs/2108.05884)<br>:house:[project](https://scenegraphgen.github.io/)

<a name="6"/>

## 6.Point Cloud(ç‚¹äº‘)
* [AdaFit: Rethinking Learning-based Normal Estimation on Point Clouds](https://arxiv.org/abs/2108.05836)<br>:star:[code](https://github.com/Runsong123/AdaFit):house:[project](https://runsong123.github.io/AdaFit/)
* ç‚¹äº‘å»å™ª
  * [Score-Based Point Cloud Denoising](https://arxiv.org/abs/2107.10981)
* ç‚¹äº‘é…å‡†
  * [HRegNet: A Hierarchical Network for Large-scale Outdoor LiDAR Point Cloud Registration](https://arxiv.org/abs/2107.11992)<br>:star:[code](https://github.com/ispc-lab/HRegNet):house:[project](https://ispc-group.github.io/hregnet)
  * [(Just) A Spoonful of Refinements Helps the Registration Error Go Down](https://arxiv.org/abs/2108.03257https://arxiv.org/abs/2108.03257)<br>:open_mouth:oral:star:[code](https://github.com/SergioRAgostinho/just-a-spoonful)
* 3Dç‚¹äº‘
  * [Unsupervised Learning of Fine Structure Generation for 3D Point Clouds by 2D Projection Matching](https://arxiv.org/abs/2108.03746)<br>:star:[code](https://github.com/chenchao15/2D_projection_matching)
* ç‚¹äº‘è¡¥å…¨
  * [SnowflakeNet: Point Cloud Completion by Snowflake Point Deconvolution with Skip-Transformer](https://arxiv.org/abs/2108.04444)

  


<a name="5"/>

## 5.Few-Shot/Zero-Shot Learning;Domain Generalization/Adaptation(å°/é›¶æ ·æœ¬å­¦ä¹ ;åŸŸé€‚åº”/æ³›åŒ–)
* åŸŸé€‚åº”
  * [Transporting Causal Mechanisms for Unsupervised Domain Adaptation](https://arxiv.org/abs/2107.11055)<br>:open_mouth:oral
  * [Generalized Source-free Domain Adaptation](https://arxiv.org/abs/2108.01614)<br>:star:[code](https://github.com/Albert0147/G-SFDA)
  * [Semantic Concentration for Domain Adaptation](https://arxiv.org/abs/2108.05720)<br>:star:[code](https://github.com/BIT-DA)
  * æ— ç›‘ç£åŸŸé€‚åº”
    * [Adversarial Unsupervised Domain Adaptation with Conditional and Label Shift: Infer, Align and Iterate](https://arxiv.org/abs/2107.13469)
    * [Recursively Conditional Gaussian for Ordinal Unsupervised Domain Adaptation](https://arxiv.org/abs/2107.13467)<br>:open_mouth:oral
  * é›¶æ ·æœ¬åŸŸé€‚åº”
    * [Zero-Shot Domain Adaptation with a Physics Prior](https://arxiv.org/abs/2108.05137)<br>:open_mouth:oral:star:[code](https://github.com/Attila94/CIConv)
* åŸŸæ³›åŒ–
  * [Domain Generalization via Gradient Surgery](https://arxiv.org/abs/2108.01621)<br>:star:[code](https://github.com/lucasmansilla/DGvGS)
* å°æ ·æœ¬
  * [Boosting the Generalization Capability in Cross-Domain Few-shot Learning via Noise-enhanced Supervised Autoencoder](https://arxiv.org/abs/2108.05028)
* Zero-Shot Learning(é›¶æ ·æœ¬å­¦ä¹ )
  * Generalized Zero-Shot Learning(å¹¿ä¹‰é›¶æ ·æœ¬å­¦ä¹ )
    * [FREE: Feature Refinement for Generalized Zero-Shot Learning](https://arxiv.org/abs/2107.13807)<br>:star:[code](https://github.com/shiming-chen/FREE)

<a name="4"/>

## 4.Neural rendering(ç¥ç»æ¸²æŸ“)
* [In-Place Scene Labelling and Understanding with Implicit Scene Representation](https://arxiv.org/abs/2103.15875)<br>:open_mouth:oral:house:[project](https://shuaifengzhi.com/Semantic-NeRF/):tv:[video](https://www.youtube.com/watch?v=FpShWO7LVbM)
* [Differentiable Surface Rendering via Non-Differentiable Sampling](https://arxiv.org/abs/2108.04886)

<a name="3"/>

## 3.Image Clustering(å›¾åƒèšç±»)
* [Clustering by Maximizing Mutual Information Across Views](https://arxiv.org/abs/2107.11635)

<a name="2"/>

## 2.Sign Language(æ‰‹è¯­è¯†åˆ«)
* [Mixed SIGNals: Sign Language Production via a Mixture of Motion Primitives](https://arxiv.org/abs/2107.11317)

<a name="1"/>

## 1.Other(å…¶å®ƒ)
* [Bias Loss for Mobile Neural Networks](https://arxiv.org/abs/2107.11170)
* [Improve Unsupervised Pretraining for Few-label Transfer](https://arxiv.org/abs/2107.12369)
* [Temporal-wise Attention Spiking Neural Networks for Event Streams Classification](https://arxiv.org/abs/2107.11711)
* [Accelerating Atmospheric Turbulence Simulation via Learned Phase-to-Space Transform](https://arxiv.org/abs/2107.11627)
* [Energy-Based Open-World Uncertainty Modeling for Confidence Calibration](https://arxiv.org/abs/2107.12628)
* [Robustness via Cross-Domain Ensembles](https://arxiv.org/abs/2103.10919)<br>:open_mouth:oral:star:[code](https://github.com/EPFL-VILAB/XDEnsembles):house:[project](https://crossdomain-ensembles.epfl.ch/):tv:[video](https://youtu.be/h0FI5Sp7y7g)
* [Warp Consistency for Unsupervised Learning of Dense Correspondences](https://arxiv.org/abs/2104.03308)<br>:open_mouth:oral:star:[code](https://github.com/PruneTruong/DenseMatching)
* [Few-Shot and Continual Learning with Attentive Independent Mechanisms](https://arxiv.org/abs/2107.14053)<br>:star:[code](https://github.com/huang50213/AIM-Fewshot-Continual)
* [Out-of-Core Surface Reconstruction via Global TGV Minimization](https://arxiv.org/abs/2107.14790)
* [ELLIPSDF: Joint Object Pose and Shape Optimization with a Bi-level Ellipsoid and Signed Distance Function Description](https://arxiv.org/abs/2108.00355)
* [Multi-scale Matching Networks for Semantic Correspondence](https://arxiv.org/abs/2108.00211)
* [Learning with Noisy Labels via Sparse Regularization](https://arxiv.org/abs/2108.00192)<br>:star:[code](https://github.com/hitcszx/lnl_sr)
* [CanvasVAE: Learning to Generate Vector Graphic Documents](https://arxiv.org/abs/2108.01249)
* [Toward Spatially Unbiased Generative Models](https://arxiv.org/abs/2108.01285)<br>:star:[code](https://github.com/jychoi118/toward_spatial_unbiased)
* [Learning Compatible Embeddings](https://arxiv.org/abs/2108.01958)<br>:star:[code](https://github.com/IrvingMeng/LCE)
* [Instance Similarity Learning for Unsupervised Feature Representation](https://arxiv.org/abs/2108.02721)<br>:star:[code](https://github.com/ZiweiWangTHU/ISL)
* [Generalizable Mixed-Precision Quantization via Attribution Rank Preservation](https://arxiv.org/abs/2108.02720)<br>:star:[code](https://github.com/ZiweiWangTHU/GMPQ)
* [Unifying Nonlocal Blocks for Neural Networks](https://arxiv.org/abs/2108.02451)<br>:star:[code](https://github.com/zh460045050/SNL_ICCV2021)
* [Impact of Aliasing on Generalization in Deep Convolutional Networks](https://arxiv.org/abs/2108.03489)
* [NASOA: Towards Faster Task-oriented Online Fine-tuning with a Zoo of Models](https://arxiv.org/abs/2108.03434)<br>:star:[code](https://github.com/NAS-OA/NASOA)
* [ProAI: An Efficient Embedded AI Hardware for Automotive Applications - a Benchmark Study](https://arxiv.org/abs/2108.05170)
* [m-RevNet: Deep Reversible Neural Networks with Momentum](https://arxiv.org/abs/2108.05862)
* [Continual Neural Mapping: Learning An Implicit Scene Representation from Sequential Observations](https://arxiv.org/abs/2108.05851)
* [MT-ORL: Multi-Task Occlusion Relationship Learning](https://arxiv.org/abs/2108.05722)<br>:star:[code](https://github.com/fengpanhe/MT-ORL)
