# ICCV2021最新信息及已接收论文/代码(持续更新)

<div align="center">
  <img src="image/ICCV2021.png"/>
</div>

官网链接：http://iccv2021.thecvf.com/home<br>
开会时间：2021年10月11日至17日<br>

# 📗📗📗在【我爱计算机视觉】微信公众号后台回复“paper”，即可收到 ICCV 2021 已收录论文的打包下载。至8月16日已公开 179 篇。

## :exclamation::exclamation::exclamation::star2::star2::star2:ICCV 2021收录论文，8月16日新增 5 篇。
* 分割
  * [Dual Path Learning for Domain Adaptation of Semantic Segmentation](https://arxiv.org/abs/2108.06337)<br>:star:[code](https://github.com/royee182/DPL)
* 目标检测
  * [Conditional DETR for Fast Training Convergence](https://arxiv.org/abs/2108.06152)
* Out-of-Distribution Detection
  * [CODEs: Chamfer Out-of-Distribution Examples against Overconfidence Issue](https://arxiv.org/abs/2108.06024)
* 对抗
  * [AGKD-BML: Defense Against Adversarial Attack by Attention Guided Knowledge Distillation and Bi-directional Metric Learning](https://arxiv.org/abs/2108.06017)<br>:star:[code](https://github.com/hongw579/AGKD-BML)
* Image quality assessment (IQA) 图像质量评估
  * [MUSIQ: Multi-scale Image Quality Transformer](https://arxiv.org/abs/2108.05997)<br>:star:[code](https://github.com/google-research/google-research/tree/master/musiq)

### 8月13日新增 18 篇。
* 知识蒸馏
  * [Distilling Holistic Knowledge with Graph Neural Networks](https://arxiv.org/abs/2108.05507)<br>:star:[code](https://github.com/wyc-ruiker/HKD)
* 姿态
  * [HandFoldingNet: A 3D Hand Pose Estimation Network Using Multiscale-Feature Guided Folding of a 2D Hand Skeleton](https://arxiv.org/abs/2108.05545)<br>:star:[code](https://github.com/cwc1260/HandFold)
* 半监督
  * [Trash to Treasure: Harvesting OOD Data with Cross-Modal Matching for Open-Set Semi-Supervised Learning](https://arxiv.org/abs/2108.05617)
* 分割
  * [LabOR: Labeling Only if Required for Domain Adaptive Semantic Segmentation](https://arxiv.org/abs/2108.05570)<br>:open_mouth:oral
  * [Vision-Language Transformer and Query Generation for Referring Segmentation](https://arxiv.org/abs/2108.05565)<br>:star:[code](https://github.com/henghuiding/Vision-Language-Transformer)
* 目标检测
  * [Oriented R-CNN for Object Detection](https://arxiv.org/abs/2108.05699)<br>:star:[code](https://github.com/jbwang1997/OBBDetection)
* 域适应
  * [Semantic Concentration for Domain Adaptation](https://arxiv.org/abs/2108.05720)<br>:star:[code](https://github.com/BIT-DA)
* 点云
  * [AdaFit: Rethinking Learning-based Normal Estimation on Point Clouds](https://arxiv.org/abs/2108.05836)<br>:star:[code](https://github.com/Runsong123/AdaFit):house:[project](https://runsong123.github.io/AdaFit/)
* 分类
  * [DiagViB-6: A Diagnostic Benchmark Suite for Vision Models in the Presence of Shortcut and Generalization Opportunities](https://arxiv.org/abs/2108.05779)
* 图像识别
  * [MicroNet: Improving Image Recognition with Extremely Low FLOPs](https://arxiv.org/abs/2108.05894)<br>:star:[code](https://github.com/liyunsheng13/micronet)
* 3D
  * [PixelSynth: Generating a 3D-Consistent Experience from a Single Image](https://arxiv.org/abs/2108.05892)<br>:star:[code](https://github.com/crockwell/pixelsynth):house:[project](https://crockwell.github.io/pixelsynth/)
  * [Towers of Babel: Combining Images, Language, and 3D Geometry for Learning Multimodal Vision](https://arxiv.org/abs/2108.05863)<br>:star:[code](https://github.com/tgxs002/wikiscenes):house:[project](https://www.cs.cornell.edu/projects/babel/)
* Metric Learning(度量学习)
  * [Towards Interpretable Deep Metric Learning with Structural Matching](https://arxiv.org/abs/2108.05889)<br>:star:[code](https://github.com/wl-zhao/DIML)
* SGG
  * [Unconditional Scene Graph Generation](https://arxiv.org/abs/2108.05884)<br>:house:[project](https://scenegraphgen.github.io/)
* 类增量学习
  * [Always Be Dreaming: A New Approach for Data-Free Class-Incremental Learning](https://arxiv.org/abs/2106.09701)<br>:newspaper:解读:[让模型实现“终生学习”，佐治亚理工学院提出Data-Free的增量学习](https://mp.weixin.qq.com/s/Fm9ufPD6rzL2VzaqpdFpjg)
* 其它
  * [m-RevNet: Deep Reversible Neural Networks with Momentum](https://arxiv.org/abs/2108.05862)
  * [Continual Neural Mapping: Learning An Implicit Scene Representation from Sequential Observations](https://arxiv.org/abs/2108.05851)
  * [MT-ORL: Multi-Task Occlusion Relationship Learning](https://arxiv.org/abs/2108.05722)<br>:star:[code](https://github.com/fengpanhe/MT-ORL)

# 目录

|:dog:|:mouse:|:hamster:|:tiger:|
|------|------|------|------|
|[41.Out-of-Distribution Detection(OOD)](#41)|
|[37.Multitask Learning(多任务学习)](#37)|[38.Weakly/Semi-Supervised/Self-supervised/Unsupervised Learning(自/半/弱监督学习)](#38)|[39.Incremental Learning(增量学习)](#39)|[40.Metric Learning(度量学习)](#40)|
|[33.Remote Sensing Images(遥感影像)](#33)|[34.Image Super-Resolution(图像超分辨率)](#34)|[35.Quantization/Pruning/Knowledge Distillation/Model Compression(量化、剪枝、蒸馏、模型压缩/扩展与优化)](#35)|[36.SLAM/AR/VR/机器人](#36)|
|[29.Image Retrieval(图像检索)](#29)|[30.Image Generation/synthesis(图像生成/合成)](#30)|[31.Style Transfer(风格迁移)](#31)|[32.语音](#32)|
|[25.Medical Image(医学影像)](#25)|[26.Image Processing(图像处理)](#26)|[27.Multi-label image recognition(多标签图像识别)](#27)|[28.Contrastive Learning(对比学习)](#28)]
|[21.Active Learning(主动学习)](#21)|[22.GAN](#22)|[23.Gaze Estimation(视线估计)](#23)|[24.Face(人脸)](#24)|
|[17.3D(三维视觉)](#17)|[18.Transformers](#18)|[19.Self-Driving Vehicles(自动驾驶)](#19)|[20.Adversarial Learning(对抗学习)](#20)|
|[13.Image Segmentation(图像分割)](#13)|[14.Object Detection(目标检测)](#13)|[15.Object Tracking(目标跟踪)](#15)|[16.Person Re-Identification(人员重识别)](#16)|
|[9.Video](#9)|[10.OCR](10)|[11.Visual Question Answering(视觉问答)](#11)|[12.Image/Fine-Grained Classification(图像/细粒度分类)](#12)|
|[5.Few-Shot/Zero-Shot Learning;Domain Generalization/Adaptation(小/零样本学习;域适应/泛化)](#5)|[6.Point Cloud(点云)](#6)|[7.Scene Graph Generation(场景图生成)](#7)|[8.Human Pose Estimation(人体姿态估计)](#8)|
|[1.Other(其它)](#1)|[2.Sign Language(手语识别)](#2)|[3.Image Clustering(图像聚类)](#3)|[4.Neural rendering(神经渲染)](#4)|




<a name="41"/>

## 41.Out-of-Distribution Detection(OOD)
* [CODEs: Chamfer Out-of-Distribution Examples against Overconfidence Issue](https://arxiv.org/abs/2108.06024)

<a name="40"/>

## 40.Metric Learning(度量学习)
* [Towards Interpretable Deep Metric Learning with Structural Matching](https://arxiv.org/abs/2108.05889)<br>:star:[code](https://github.com/wl-zhao/DIML)

<a name="39"/>

## 39.Incremental Learning(增量学习)
* 类增量学习
  * [Always Be Dreaming: A New Approach for Data-Free Class-Incremental Learning](https://arxiv.org/abs/2106.09701)<br>:newspaper:解读:[让模型实现“终生学习”，佐治亚理工学院提出Data-Free的增量学习](https://mp.weixin.qq.com/s/Fm9ufPD6rzL2VzaqpdFpjg)

<a name="38"/>

## 38.Weakly/Semi-Supervised/Self-supervised/Unsupervised Learning(自/半/弱监督学习)
* 半监督
  * [Trash to Treasure: Harvesting OOD Data with Cross-Modal Matching for Open-Set Semi-Supervised Learning](https://arxiv.org/abs/2108.05617)

<a name="37"/>

## 37.Multitask Learning(多任务学习)
* [MultiTask-CenterNet (MCN): Efficient and Diverse Multitask Learning using an Anchor Free Approach](https://arxiv.org/abs/2108.05060)

<a name="36"/>

## 36.SLAM/AR/VR/机器人
* 虚拟试穿  
  * [M3D-VTON: A Monocular-to-3D Virtual Try-On Network](https://arxiv.org/abs/2108.05126)

<a name="35"/>

## 35.Quantization/Pruning/Knowledge Distillation/Model Compression(量化、剪枝、蒸馏、模型压缩/扩展与优化)
* 知识蒸馏
  * [Distilling Holistic Knowledge with Graph Neural Networks](https://arxiv.org/abs/2108.05507)<br>:star:[code](https://github.com/wyc-ruiker/HKD)


<a name="34"/>

## 34.Image Super-Resolution(图像超分辨率)
* [Mutual Affine Network for Spatially Variant Kernel Estimation in Blind Image Super-Resolution](https://arxiv.org/abs/2108.05302)<br>:star:[code](https://github.com/JingyunLiang/MANet)
* [Hierarchical Conditional Flow: A Unified Framework for Image Super-Resolution and Image Rescaling](https://arxiv.org/abs/2108.05301)<br>:star:[code](https://github.com/JingyunLiang/HCFlow)

<a name="33"/>

## 33.Remote Sensing Images(遥感影像)
* [SUNet: Symmetric Undistortion Network for Rolling Shutter Correction](https://arxiv.org/abs/2108.04775)

<a name="32"/>

## 32.语音
* [The Right to Talk: An Audio-Visual Transformer Approach](https://arxiv.org/abs/2108.03256)<br>:star:[code](https://github.com/uark-cviu/Right2Talk)

<a name="31"/>

## 31.Style Transfer(风格迁移)
* [AdaAttN: Revisit Attention Mechanism in Arbitrary Neural Style Transfer](https://arxiv.org/abs/2108.03647)<br>:star:[code](https://github.com/Huage001/AdaAttN)
* [Domain-Aware Universal Style Transfer](https://arxiv.org/abs/2108.04441)<br>:star:[code](https://github.com/Kibeom-Hong/Domain-Aware-Style-Transfer)

<a name="30"/>

## 30.Image Generation/synthesis(图像生成/合成)
  * [ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2108.02938)<br>:open_mouth:oral

<a name="29"/>

## 29.Image Retrieval(图像检索)
  * [DOLG: Single-Stage Image Retrieval with Deep Orthogonal Fusion of Local and Global Features](https://arxiv.org/abs/2108.02927)<br>:star:[code](https://github.com/feymanpriv/DOLG)
  * [Image Retrieval on Real-life Images with Pre-trained Vision-and-Language Models](https://arxiv.org/abs/2108.04024)<br>:star:[code](https://github.com/Cuberick-Orion/CIRR):house:[project](https://cuberick-orion.github.io/CIRR/)


<a name="28"/>

## 28.Contrastive Learning(对比学习)
  * [Improving Contrastive Learning by Visualizing Feature Transformation](https://arxiv.org/abs/2108.02982)<br>:open_mouth:oral:star:[code](https://github.com/DTennant/CL-Visualizing-Feature-Transformation)

<a name="27"/>

## 27.Multi-label image recognition(多标签图像识别)
* [Residual Attention: A Simple but Effective Method for Multi-Label Recognition](https://arxiv.org/abs/2108.02456)

<a name="26"/>

## 26.Image Processing(图像处理)

* 边缘检测
  * [RINDNet: Edge Detection for Discontinuity in Reflectance, Illumination, Normal and Depth](https://arxiv.org/abs/2108.00616)<br>:open_mouth:oral:star:[code](https://github.com/MengyangPu/RINDNet)
* 图像识别
  * [MicroNet: Improving Image Recognition with Extremely Low FLOPs](https://arxiv.org/abs/2108.05894)<br>:star:[code](https://github.com/liyunsheng13/micronet)
* 图像去模糊
  * [Rethinking Coarse-to-Fine Approach in Single Image Deblurring](https://arxiv.org/abs/2108.05054)<br>:star:[code](https://github.com/chosj95/MIMO-UNet)
* Image quality assessment(图像质量评估IQA)
  * [MUSIQ: Multi-scale Image Quality Transformer](https://arxiv.org/abs/2108.05997)<br>:star:[code](https://github.com/google-research/google-research/tree/master/musiq)


<a name="25"/>

## 25.Medical Image(医学影像)
* 医学图像分割
  * [Recurrent Mask Refinement for Few-Shot Medical Image Segmentation](https://arxiv.org/abs/2108.00622)<br>:star:[code](https://github.com/uci-cbcl/RP-Net)
  
<a name="24"/>

## 24.Face(人脸)
* 人脸造假检测
  * [OpenForensics: Large-Scale Challenging Dataset For Multi-Face Forgery Detection And Segmentation In-The-Wild](https://arxiv.org/abs/2107.14480)<br>:house:[project](https://sites.google.com/view/ltnghia/research/openforensics)
* 人脸合成
  * [Disentangled Lifespan Face Synthesis](https://arxiv.org/abs/2108.02874)<br>:star:[code](https://github.com/SenHe/DLFS):house:[project](https://senhe.github.io/projects/iccv_2021_lifespan_face/):tv:[video](https://youtu.be/uklX03ns0m0)
* 人脸识别                                                                                      
  * [PASS: Protected Attribute Suppression System for Mitigating Bias in Face Recognition](https://arxiv.org/abs/2108.03764)
* Face perception面部感知
 * [Learning Facial Representations from the Cycle-consistency of Face](https://arxiv.org/abs/2108.03427)<br>:star:[code](https://github.com/JiaRenChang/FaceCycle)

<a name="23"/>

## 23.Gaze Estimation(视线估计)
* [Generalizing Gaze Estimation with Outlier-guided Collaborative Adaptation](https://arxiv.org/abs/2107.13780)<br>:star:[code](https://github.com/DreamtaleCore/PnP-GA)

<a name="22"/>

## 22.GAN
* [Sketch Your Own GAN](https://arxiv.org/abs/2108.02774)<br>:star:[code](https://github.com/peterwang512/GANSketching):house:[project](https://peterwang512.github.io/GANSketching/)
* GAN inversion(GAN逆映射)
  * [From Continuity to Editability: Inverting GANs with Consecutive Images](https://arxiv.org/abs/2107.13812)<br>:star:[code](https://github.com/cnnlstm/InvertingGANs_with_ConsecutiveImgs)

<a name="21"/>

## 21.Active Learning(主动学习)
* [Semi-Supervised Active Learning with Temporal Output Discrepancy](https://arxiv.org/abs/2107.14153)<br>:star:[code](https://github.com/siyuhuang/TOD)

<a name="20"/>

## 20.Adversarial Learning(对抗学习)
* [Feature Importance-aware Transferable Adversarial Attacks](https://arxiv.org/abs/2107.14185)<br>:star:[code](https://github.com/hcguoO0/FIA)
* [TkML-AP: Adversarial Attacks to Top-k Multi-Label Learning](https://arxiv.org/abs/2108.00146)
* [Meta Gradient Adversarial Attack](https://arxiv.org/abs/2108.04204)
* [AGKD-BML: Defense Against Adversarial Attack by Attention Guided Knowledge Distillation and Bi-directional Metric Learning](https://arxiv.org/abs/2108.06017)<br>:star:[code](https://github.com/hongw579/AGKD-BML)

<a name="19"/>

## 19.Self-Driving Vehicles(自动驾驶)
* Human trajectory prediction(人体轨迹预测)
  * [Personalized Trajectory Prediction via Distribution Discrimination](https://arxiv.org/abs/2107.14204)<br>:star:[code](https://github.com/CHENGY12/DisDis)
  * [Human Trajectory Prediction via Counterfactual Analysis](https://arxiv.org/abs/2107.14202)(https://github.com/CHENGY12/CausalHTP)
* 轨迹预测
  * [Unlimited Neighborhood Interaction for Heterogeneous Trajectory Prediction](https://arxiv.org/abs/2108.00238)
* 运动预测
  * [RAIN: Reinforced Hybrid Attention Inference Network for Motion Forecasting](https://arxiv.org/abs/2108.01316)<br>:house:[project](https://jiachenli94.github.io/publications/RAIN/)
  * [SLAMP: Stochastic Latent Appearance and Motion Prediction](https://arxiv.org/abs/2108.02760)<br>:house:[project](https://peterwang512.github.io/GANSketching/)(https://kuis-ai.github.io/slamp/)


<a name="18"/>

## 18.Transformers
* [Generic Attention-model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers](https://arxiv.org/abs/2103.15679)<br>:open_mouth:oral:star:[code](https://github.com/hila-chefer/Transformer-MM-Explainability)<br>:newspaper:解读:[ICCV2021 Oral-TAU&Facebook提出了通用的Attention模型可解释性](https://mp.weixin.qq.com/s/3skb8XMiwM3QtdH7ZazoYg)
* [PlaneTR: Structure-Guided Transformers for 3D Plane Recovery](https://arxiv.org/abs/2107.13108)<br>:star:[code](https://github.com/IceTTTb/PlaneTR3D)
* [Rethinking and Improving Relative Position Encoding for Vision Transformer](https://arxiv.org/abs/2107.14222)<br>:star:[code](https://github.com/microsoft/AutoML/tree/main/iRPE)
* [Vision Transformer with Progressive Sampling](https://arxiv.org/abs/2108.01684)
* [Paint Transformer: Feed Forward Neural Painting with Stroke Prediction](https://arxiv.org/abs/2108.03798)<br>:open_mouth:oral:star:[code](https://github.com/Huage001/PaintTransformer)
* 密集预测
  * [Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions](https://arxiv.org/abs/2102.12122)<br>:open_mouth:oral:star:[code](https://github.com/whai362/PVT)<br>:newspaper:解读:[大白话Pyramid Vision Transformer](https://mp.weixin.qq.com/s/oJHZWmStQYYzEEOveiuQrQ)



<a name="17"/>

## 17.3D(三维视觉)
* [Discovering 3D Parts from Image Collections](https://arxiv.org/abs/2107.13629)<br>:open_mouth:oral:star:[code](https://github.com/chhankyao/lpd):house:[project](https://chhankyao.github.io/lpd/):tv:[video](https://youtu.be/erNQANNwK6k)
* [PixelSynth: Generating a 3D-Consistent Experience from a Single Image](https://arxiv.org/abs/2108.05892)<br>:star:[code](https://github.com/crockwell/pixelsynth):house:[project](https://crockwell.github.io/pixelsynth/)
* [Towers of Babel: Combining Images, Language, and 3D Geometry for Learning Multimodal Vision](https://arxiv.org/abs/2108.05863)<br>:star:[code](https://github.com/tgxs002/wikiscenes):house:[project](https://www.cs.cornell.edu/projects/babel/)
* Monocular Depth Estimation(单目深度估计)
  * [MonoIndoor: Towards Good Practice of Self-Supervised Monocular Depth Estimation for Indoor Environments](https://arxiv.org/abs/2107.12429)
  * [Regularizing Nighttime Weirdness: Efficient Self-supervised Monocular Depth Estimation in the Dark](https://arxiv.org/abs/2108.03830)<br>:star:[code](https://github.com/w2kun/RNW)
  * [Towards Interpretable Deep Networks for Monocular Depth Estimation](https://arxiv.org/abs/2108.05312)<br>:star:[code](https://github.com/youzunzhi/InterpretableMDE)



<a name="16"/>

## 16.Person Re-Identification(人员重识别)
* [Spatio-Temporal Representation Factorization for Video-based Person Re-Identification](https://arxiv.org/abs/2107.11878)
* [Learning Instance-level Spatial-Temporal Patterns for Person Re-identification](https://arxiv.org/abs/2108.00171)<br>:star:[code](https://github.com/RenMin1991/cleaned-DukeMTMC-reID/)
* [Towards Discriminative Representation Learning for Unsupervised Person Re-identification](https://arxiv.org/abs/2108.03439)
* 域适应人员重识别
  * [IDM: An Intermediate Domain Module for Domain Adaptive Person Re-ID](https://arxiv.org/abs/2108.02413)<br>:open_mouth:oral:star:[code](https://github.com/SikaStar/IDM)
* Crowd Counting(拥挤人群计数)
  * [Rethinking Counting and Localization in Crowds:A Purely Point-Based Framework](https://arxiv.org/abs/2107.12746)<br>:open_mouth:oral:star:[code](https://github.com/TencentYoutuResearch)
  * [Uniformity in Heterogeneity:Diving Deep into Count Interval Partition for Crowd Counting](https://arxiv.org/abs/2107.12619)<br>:star:[code](https://github.com/TencentYoutuResearch)
  * [Spatial Uncertainty-Aware Semi-Supervised Crowd Counting](https://arxiv.org/abs/2107.13271)
* Person Search
  * [ASMR: Learning Attribute-Based Person Search with Adaptive Semantic Margin Regularizer](https://arxiv.org/abs/2108.04533)<br>:house:[project](http://cvlab.postech.ac.kr/research/ASMR/)


<a name="15"/>

## 15.Object Tracking(目标跟踪)
* [Saliency-Associated Object Tracking](https://arxiv.org/abs/2108.03637)
* [Box-Aware Feature Enhancement for Single Object Tracking on Point Clouds](https://arxiv.org/abs/2108.04728)<br>:star:[code](https://github.com/Ghostish/BAT)
* 视觉目标跟踪
  * [Learning to Adversarially Blur Visual Object Tracking](https://arxiv.org/abs/2107.12085)<br>:star:[code](https://github.com/tsingqguo/ABA)
  * [Learn to Match: Automatic Matching Network Design for Visual Tracking](https://arxiv.org/abs/2108.00803)<br>:star:[code](https://github.com/JudasDie/SOTS)
  * [Video Annotation for Visual Tracking via Selection and Refinement](https://arxiv.org/abs/2108.03821)<br>:star:[code](https://github.com/Daikenan/VASR)
* 卫星图像跟踪 
  * [HiFT: Hierarchical Feature Transformer for Aerial Tracking](https://arxiv.org/abs/2108.00202)<br>:star:[code](https://github.com/vision4robotics/HiFT)

<a name="14"/>

## 14.Object Detection(目标检测)
* [Rank & Sort Loss for Object Detection and Instance Segmentation](https://arxiv.org/abs/2107.11669)<br>:open_mouth:oral:star:[code](https://github.com/kemaloksuz/RankSortLoss)
* [MDETR : Modulated Detection for End-to-End Multi-Modal Understanding](https://arxiv.org/abs/2104.12763)<br>:open_mouth:oral:star:[code](https://github.com/ashkamath/mdetr)
* [SimROD: A Simple Adaptation Method for Robust Object Detection](https://arxiv.org/abs/2107.13389)<br>:open_mouth:oral
* [GraphFPN: Graph Feature Pyramid Network for Object Detection](https://arxiv.org/abs/2108.00580)
* [Fast Convergence of DETR with Spatially Modulated Co-Attention](https://arxiv.org/abs/2108.02404)<br>:star:[code](https://github.com/gaopengcuhk/SMCA-DETR)
* [Oriented R-CNN for Object Detection](https://arxiv.org/abs/2108.05699)<br>:star:[code](https://github.com/jbwang1997/OBBDetection) 
* [Conditional DETR for Fast Training Convergence](https://arxiv.org/abs/2108.06152)
* 3D目标检测
  * [Geometry Uncertainty Projection Network for Monocular 3D Object Detection](https://arxiv.org/abs/2107.13774)
  * [Fog Simulation on Real LiDAR Point Clouds for 3D Object Detection in Adverse Weather](https://arxiv.org/abs/2108.05249)<br>:star:[code](https://github.com/MartinHahner/LiDAR_fog_sim):house:[project](https://www.trace.ethz.ch/publications/2021/lidar_fog_simulation/)
* 目标定位
  * 弱监督目标定位
    * [Normalization Matters in Weakly Supervised Object Localization](https://arxiv.org/abs/2107.13221)
* Anomaly Detection(图像异常检测)
  * [Divide-and-Assemble: Learning Block-wise Memory for Unsupervised Anomaly Detection](https://arxiv.org/abs/2107.13118)
* 弱监督目标检测
  * [Boosting Weakly Supervised Object Detection via Learning Bounding Box Adjusters](https://arxiv.org/abs/2108.01499)<br>:star:[code](https://github.com/DongSky/lbba_boosted_wsod)
* OOD 检测
  * [Triggering Failures: Out-Of-Distribution detection by learning from local adversarial attacks in Semantic Segmentation](https://arxiv.org/abs/2108.01634)<br>:star:[code](https://github.com/valeoai/obsnet)
* 显著目标检测
  * [Disentangled High Quality Salient Object Detection](https://arxiv.org/abs/2108.03551)


<a name="13"/>

## 13.Image Segmentation(图像分割)
* [Standardized Max Logits: A Simple yet Effective Approach for Identifying Unexpected Road Obstacles in Urban-Scene Segmentation](https://arxiv.org/abs/2107.11264)<br>:open_mouth:oral
* [TransForensics: Image Forgery Localization with Dense Self-Attention](https://arxiv.org/abs/2108.03871)
* 语义分割
  * [Re-distributing Biased Pseudo Labels for Semi-supervised Semantic Segmentation: A Baseline Investigation](https://arxiv.org/abs/2107.11279)<br>:open_mouth:oral:star:[code](https://github.com/CVMI-Lab/DARS)
  * [Personalized Image Semantic Segmentation](https://arxiv.org/abs/2107.13978)<br>:star:[code](https://github.com/zhangyuygss/PIS)
  * [RECALL: Replay-based Continual Learning in Semantic Segmentation](https://arxiv.org/abs/2108.03673)
  * [Deep Metric Learning for Open World Semantic Segmentation](https://arxiv.org/abs/2108.04562)
  * [LabOR: Labeling Only if Required for Domain Adaptive Semantic Segmentation](https://arxiv.org/abs/2108.05570)<br>:open_mouth:oral
  * [Dual Path Learning for Domain Adaptation of Semantic Segmentation](https://arxiv.org/abs/2108.06337)<br>:star:[code](https://github.com/royee182/DPL)
  * 小样本语义分割
    * [Simpler is Better: Few-shot Semantic Segmentation with Classifier Weight Transformer](https://arxiv.org/abs/2108.03032)<br>:star:[code](https://github.com/zhiheLu/CWT-for-FSS)
    * [Learning Meta-class Memory for Few-Shot Semantic Segmentation](https://arxiv.org/abs/2108.02958)
  * 3D语义分割
    * [VMNet: Voxel-Mesh Network for Geodesic-Aware 3D Semantic Segmentation](https://arxiv.org/abs/2107.13824)<br>:open_mouth:oral:star:[code](https://github.com/hzykent/VMNet)
  * 视频语义分割
    * [Domain Adaptive Video Segmentation via Temporal Consistency Regularization](https://arxiv.org/abs/2107.11004)<br>:star:[code](https://github.com/Dayan-Guan/DA-VSN)
  * 弱监督语义分割
    * [Leveraging Auxiliary Tasks with Affinity Learning for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2107.11787)<br>:star:[code](https://github.com/xulianuwa/AuxSegNet)
    * [Complementary Patch for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2108.03852)
  * 点云语义分割
    * [ReDAL: Region-based and Diversity-aware Active Learning for Point Cloud Semantic Segmentation](https://arxiv.org/abs/2107.11769)
* 实例分割
  * [Rank & Sort Loss for Object Detection and Instance Segmentation](https://arxiv.org/abs/2107.11669)<br>:open_mouth:oral:star:[code](https://github.com/kemaloksuz/RankSortLoss)
  * 3D实例分割
    * [Hierarchical Aggregation for 3D Instance Segmentation](https://arxiv.org/abs/2108.02350)<br>:star:[code](https://github.com/hustvl/HAIS)
* 小样本分割
  * [Mining Latent Classes for Few-shot Segmentation](https://arxiv.org/abs/2103.15402)<br>:open_mouth:oral:star:[code](https://github.com/LiheYoung/MiningFSS)
* Human Motion Segmentation(人体运动分割)
  * [Graph Constrained Data Representation Learning for Human Motion Segmentation](https://arxiv.org/abs/2107.13362)
* 点云分割
  * [Learning with Noisy Labels for Robust Point Cloud Segmentation](https://arxiv.org/abs/2107.14230)<br>:open_mouth:oral:star:[code](https://github.com/pleaseconnectwifi/PNAL):house:[project](https://shuquanye.com/PNAL_website/)
  * [DRINet: A Dual-Representation Iterative Learning Network for Point Cloud Segmentation](https://arxiv.org/abs/2108.04023)
* 视频目标分割(VOS)
  * [Full-Duplex Strategy for Video Object Segmentation](https://arxiv.org/abs/2108.03151)<br>:house:[project](http://dpfan.net/FSNet/)
  * [Joint Inductive and Transductive Learning for Video Object Segmentation](https://arxiv.org/abs/2108.03679)<br>:star:[code](https://github.com/maoyunyao/JOINT)
* 语义场景分割 
  * [BiMaL: Bijective Maximum Likelihood Approach to Domain Adaptation in Semantic Scene Segmentation](https://arxiv.org/abs/2108.03267)<br>:star:[code](https://github.com/uark-cviu/BiMaL)
* Referring Segmentation(基于文本的分割) 
  * [Vision-Language Transformer and Query Generation for Referring Segmentation](https://arxiv.org/abs/2108.05565)<br>:star:[code](https://github.com/henghuiding/Vision-Language-Transformer)



<a name="12"/>

## 12.Image/Fine-Grained Classification(图像/细粒度分类) 
* [DiagViB-6: A Diagnostic Benchmark Suite for Vision Models in the Presence of Shortcut and Generalization Opportunities](https://arxiv.org/abs/2108.05779)
* 长尾识别
  * [Parametric Contrastive Learning](https://arxiv.org/abs/2107.12028)<br>:star:[code](https://github.com/jiequancui/Parametric-Contrastive-Learning)
  * [ACE: Ally Complementary Experts for Solving Long-Tailed Recognition in One-Shot](https://arxiv.org/abs/2108.02385)<br>:open_mouth:oral:star:[code](https://github.com/jrcai/ACE)
* 细粒度
  * [Webly Supervised Fine-Grained Recognition: Benchmark Datasets and An Approach](https://arxiv.org/abs/2108.02399)<br>:star:[code](https://github.com/NUST-Machine-Intelligence-Laboratory/weblyFG-dataset)
  * [Learning Canonical 3D Object Representation for Fine-Grained Recognition](https://arxiv.org/abs/2108.04628)
* 小样本分类
  * [Transductive Few-Shot Classification on the Oblique Manifold](https://arxiv.org/abs/2108.04009)

<a name="11"/>

## 11.Visual Question Answering(视觉问答)
* [Greedy Gradient Ensemble for Robust Visual Question Answering](https://arxiv.org/abs/2107.12651)<br>:star:[code](https://github.com/GeraldHan/GGE)
* video question answering
  * [Just Ask: Learning to Answer Questions from Millions of Narrated Videos](https://arxiv.org/abs/2012.00451)<br>:open_mouth:oral:star:[code](https://github.com/antoyang/just-ask):house:[project](https://antoyang.github.io/just-ask.html)

<a name="10"/>

## 10.OCR
* [Joint Visual Semantic Reasoning: Multi-Stage Decoder for Text Recognition](https://arxiv.org/abs/2107.12090)
* [Text is Text, No Matter What: Unifying Text Recognition using Knowledge Distillation](https://arxiv.org/abs/2107.12087)
* [Towards the Unseen: Iterative Text Recognition by Distilling from Errors](https://arxiv.org/abs/2107.12081)
* [Adaptive Boundary Proposal Network for Arbitrary Shape Text Detection](https://arxiv.org/abs/2107.12664)<br>:star:[code](https://github.com/GXYM/TextBPN)

<a name="9"/>

## 9.Video
* Action Detection and Recognition(人体动作检测与识别)
  * [Channel-wise Topology Refinement Graph Convolution for Skeleton-Based Action Recognition](https://arxiv.org/abs/2107.12213)<br>:star:[code](https://github.com/Uason-Chen/CTR-GCN)
  * [MGSampler: An Explainable Sampling Strategy for Video Action Recognition](https://arxiv.org/abs/2104.09952)
  * [Skeleton Cloud Colorization for Unsupervised 3D Action Representation Learning](https://arxiv.org/abs/2108.01959)
  * 零样本动作识别
    * [Elaborative Rehearsal for Zero-shot Action Recognition](https://arxiv.org/abs/2108.02833)<br>:star:[code](https://github.com/DeLightCMU/ElaborativeRehearsal)
  * Temporal Action Localization(时序动作定位)
    * [Enriching Local and Global Contexts for Temporal Action Localization](https://arxiv.org/abs/2107.12960)
    * [Learning Action Completeness from Points for Weakly-supervised Temporal Action Localization](https://arxiv.org/abs/2108.05029)<br>:open_mouth:oral:star:[code](https://github.com/Pilhyeon)
* Video Rescaling
  * [Self-Conditioned Probabilistic Learning of Video Rescaling](https://arxiv.org/abs/2107.11639)
* Video activity localisation
  * [Cross-Sentence Temporal and Semantic Relations in Video Activity Localisation](https://arxiv.org/abs/2107.11443)
* 视频修复
  * [Internal Video Inpainting by Implicit Long-range Propagation](https://arxiv.org/abs/2108.01912)<br>:star:[code](https://github.com/Tengfei-Wang/Implicit-Internal-Video-Inpainting):house:[project](https://tengfei-wang.github.io/Implicit-Internal-Video-Inpainting/)
* 视频分析
  * 视频表征学习
    * [Enhancing Self-supervised Video Representation Learning via Multi-level Feature Optimization](https://arxiv.org/abs/2108.02183)
* 视频剪辑
  * [Learning to Cut by Watching Movies](https://arxiv.org/abs/2108.04294)<br>:star:[code](https://github.com/PardoAlejo/LearningToCut):house:[project](https://www.alejandropardo.net/publication/learning-to-cut/) 



<a name="8"/>

## 8.Human Pose Estimation(人体姿态估计)
* [Human Pose Regression with Residual Log-likelihood Estimation](https://arxiv.org/abs/2107.11291)<br>:open_mouth:oral:star:[code](https://github.com/Jeff-sjtu/res-loglikelihood-regression)
* [Online Knowledge Distillation for Efficient Pose Estimation](https://arxiv.org/abs/2108.02092)
* 3D 人体姿态估计
  * [PyMAF: 3D Human Pose and Shape Regression with Pyramidal Mesh Alignment Feedback Loop](https://arxiv.org/abs/2103.16507)<br>:open_mouth:oral:star:[code](https://github.com/HongwenZhang/PyMAF):house:[project](https://hongwenzhang.github.io/pymaf/)
  * [HuMoR: 3D Human Motion Model for Robust Pose Estimation](https://arxiv.org/abs/2105.04668)<br>:open_mouth:oral:house:[project](https://geometry.stanford.edu/projects/humor/):tv:[video](https://youtu.be/5VWirxUHG0Y)
  * [Probabilistic Monocular 3D Human Pose Estimation with Normalizing Flows](https://arxiv.org/abs/2107.13788)<br>:star:[code](https://github.com/twehrbein/Probabilistic-Monocular-3D-Human-Pose-Estimation-with-Normalizing-Flows)
* 手势识别
  * [Hand Image Understanding via Deep Multi-Task Learning](https://arxiv.org/abs/2107.11646)
* 3D 手部姿态
  * [HandFoldingNet: A 3D Hand Pose Estimation Network Using Multiscale-Feature Guided Folding of a 2D Hand Skeleton](https://arxiv.org/abs/2108.05545)<br>:star:[code](https://github.com/cwc1260/HandFold)


<a name="7"/>

## 7.Scene Graph Generation(场景图生成)
* [Spatial-Temporal Transformer for Dynamic Scene Graph Generation](https://arxiv.org/abs/2107.12309)
* [Unconditional Scene Graph Generation](https://arxiv.org/abs/2108.05884)<br>:house:[project](https://scenegraphgen.github.io/)

<a name="6"/>

## 6.Point Cloud(点云)
* [AdaFit: Rethinking Learning-based Normal Estimation on Point Clouds](https://arxiv.org/abs/2108.05836)<br>:star:[code](https://github.com/Runsong123/AdaFit):house:[project](https://runsong123.github.io/AdaFit/)
* 点云去噪
  * [Score-Based Point Cloud Denoising](https://arxiv.org/abs/2107.10981)
* 点云配准
  * [HRegNet: A Hierarchical Network for Large-scale Outdoor LiDAR Point Cloud Registration](https://arxiv.org/abs/2107.11992)<br>:star:[code](https://github.com/ispc-lab/HRegNet):house:[project](https://ispc-group.github.io/hregnet)
  * [(Just) A Spoonful of Refinements Helps the Registration Error Go Down](https://arxiv.org/abs/2108.03257https://arxiv.org/abs/2108.03257)<br>:open_mouth:oral:star:[code](https://github.com/SergioRAgostinho/just-a-spoonful)
* 3D点云
  * [Unsupervised Learning of Fine Structure Generation for 3D Point Clouds by 2D Projection Matching](https://arxiv.org/abs/2108.03746)<br>:star:[code](https://github.com/chenchao15/2D_projection_matching)
* 点云补全
  * [SnowflakeNet: Point Cloud Completion by Snowflake Point Deconvolution with Skip-Transformer](https://arxiv.org/abs/2108.04444)

  


<a name="5"/>

## 5.Few-Shot/Zero-Shot Learning;Domain Generalization/Adaptation(小/零样本学习;域适应/泛化)
* 域适应
  * [Transporting Causal Mechanisms for Unsupervised Domain Adaptation](https://arxiv.org/abs/2107.11055)<br>:open_mouth:oral
  * [Generalized Source-free Domain Adaptation](https://arxiv.org/abs/2108.01614)<br>:star:[code](https://github.com/Albert0147/G-SFDA)
  * [Semantic Concentration for Domain Adaptation](https://arxiv.org/abs/2108.05720)<br>:star:[code](https://github.com/BIT-DA)
  * 无监督域适应
    * [Adversarial Unsupervised Domain Adaptation with Conditional and Label Shift: Infer, Align and Iterate](https://arxiv.org/abs/2107.13469)
    * [Recursively Conditional Gaussian for Ordinal Unsupervised Domain Adaptation](https://arxiv.org/abs/2107.13467)<br>:open_mouth:oral
  * 零样本域适应
    * [Zero-Shot Domain Adaptation with a Physics Prior](https://arxiv.org/abs/2108.05137)<br>:open_mouth:oral:star:[code](https://github.com/Attila94/CIConv)
* 域泛化
  * [Domain Generalization via Gradient Surgery](https://arxiv.org/abs/2108.01621)<br>:star:[code](https://github.com/lucasmansilla/DGvGS)
* 小样本
  * [Boosting the Generalization Capability in Cross-Domain Few-shot Learning via Noise-enhanced Supervised Autoencoder](https://arxiv.org/abs/2108.05028)
* Zero-Shot Learning(零样本学习)
  * Generalized Zero-Shot Learning(广义零样本学习)
    * [FREE: Feature Refinement for Generalized Zero-Shot Learning](https://arxiv.org/abs/2107.13807)<br>:star:[code](https://github.com/shiming-chen/FREE)

<a name="4"/>

## 4.Neural rendering(神经渲染)
* [In-Place Scene Labelling and Understanding with Implicit Scene Representation](https://arxiv.org/abs/2103.15875)<br>:open_mouth:oral:house:[project](https://shuaifengzhi.com/Semantic-NeRF/):tv:[video](https://www.youtube.com/watch?v=FpShWO7LVbM)
* [Differentiable Surface Rendering via Non-Differentiable Sampling](https://arxiv.org/abs/2108.04886)

<a name="3"/>

## 3.Image Clustering(图像聚类)
* [Clustering by Maximizing Mutual Information Across Views](https://arxiv.org/abs/2107.11635)

<a name="2"/>

## 2.Sign Language(手语识别)
* [Mixed SIGNals: Sign Language Production via a Mixture of Motion Primitives](https://arxiv.org/abs/2107.11317)

<a name="1"/>

## 1.Other(其它)
* [Bias Loss for Mobile Neural Networks](https://arxiv.org/abs/2107.11170)
* [Improve Unsupervised Pretraining for Few-label Transfer](https://arxiv.org/abs/2107.12369)
* [Temporal-wise Attention Spiking Neural Networks for Event Streams Classification](https://arxiv.org/abs/2107.11711)
* [Accelerating Atmospheric Turbulence Simulation via Learned Phase-to-Space Transform](https://arxiv.org/abs/2107.11627)
* [Energy-Based Open-World Uncertainty Modeling for Confidence Calibration](https://arxiv.org/abs/2107.12628)
* [Robustness via Cross-Domain Ensembles](https://arxiv.org/abs/2103.10919)<br>:open_mouth:oral:star:[code](https://github.com/EPFL-VILAB/XDEnsembles):house:[project](https://crossdomain-ensembles.epfl.ch/):tv:[video](https://youtu.be/h0FI5Sp7y7g)
* [Warp Consistency for Unsupervised Learning of Dense Correspondences](https://arxiv.org/abs/2104.03308)<br>:open_mouth:oral:star:[code](https://github.com/PruneTruong/DenseMatching)
* [Few-Shot and Continual Learning with Attentive Independent Mechanisms](https://arxiv.org/abs/2107.14053)<br>:star:[code](https://github.com/huang50213/AIM-Fewshot-Continual)
* [Out-of-Core Surface Reconstruction via Global TGV Minimization](https://arxiv.org/abs/2107.14790)
* [ELLIPSDF: Joint Object Pose and Shape Optimization with a Bi-level Ellipsoid and Signed Distance Function Description](https://arxiv.org/abs/2108.00355)
* [Multi-scale Matching Networks for Semantic Correspondence](https://arxiv.org/abs/2108.00211)
* [Learning with Noisy Labels via Sparse Regularization](https://arxiv.org/abs/2108.00192)<br>:star:[code](https://github.com/hitcszx/lnl_sr)
* [CanvasVAE: Learning to Generate Vector Graphic Documents](https://arxiv.org/abs/2108.01249)
* [Toward Spatially Unbiased Generative Models](https://arxiv.org/abs/2108.01285)<br>:star:[code](https://github.com/jychoi118/toward_spatial_unbiased)
* [Learning Compatible Embeddings](https://arxiv.org/abs/2108.01958)<br>:star:[code](https://github.com/IrvingMeng/LCE)
* [Instance Similarity Learning for Unsupervised Feature Representation](https://arxiv.org/abs/2108.02721)<br>:star:[code](https://github.com/ZiweiWangTHU/ISL)
* [Generalizable Mixed-Precision Quantization via Attribution Rank Preservation](https://arxiv.org/abs/2108.02720)<br>:star:[code](https://github.com/ZiweiWangTHU/GMPQ)
* [Unifying Nonlocal Blocks for Neural Networks](https://arxiv.org/abs/2108.02451)<br>:star:[code](https://github.com/zh460045050/SNL_ICCV2021)
* [Impact of Aliasing on Generalization in Deep Convolutional Networks](https://arxiv.org/abs/2108.03489)
* [NASOA: Towards Faster Task-oriented Online Fine-tuning with a Zoo of Models](https://arxiv.org/abs/2108.03434)<br>:star:[code](https://github.com/NAS-OA/NASOA)
* [ProAI: An Efficient Embedded AI Hardware for Automotive Applications - a Benchmark Study](https://arxiv.org/abs/2108.05170)
* [m-RevNet: Deep Reversible Neural Networks with Momentum](https://arxiv.org/abs/2108.05862)
* [Continual Neural Mapping: Learning An Implicit Scene Representation from Sequential Observations](https://arxiv.org/abs/2108.05851)
* [MT-ORL: Multi-Task Occlusion Relationship Learning](https://arxiv.org/abs/2108.05722)<br>:star:[code](https://github.com/fengpanhe/MT-ORL)
